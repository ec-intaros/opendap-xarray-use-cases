# Subset 2003 Analysis with Xarray

This Notebook provides an overview, as well as practical examples, to access and analyse a subset of NetCDF data from available campaigns collected in the year 2003. This subset of data has been prepared and uploaded on the Hyrax server (https://opendap.terradue.com/hyrax/data/subset_2003/), where it can be accessed directly.

The main steps for executing the Notebook are described below. 

## Set-up
The first step is to define the url of the server to use. Two options are provided, one for HYRAX and one for THREDDS:
* hyrax: https://opendap.terradue.com/hyrax/data/subset_2003/
* thredds: https://opendap.terradue.com/thredds/dodsC/subset_2003/

Subsequently, the *year* and the *platform codes* are defined. This information is needed, and needs to be known a priori, as it allows comleting the url to access each specific NetCDF file. The naming convention of the NetCDF files is:
```58<platform_code>_CTD_<year>.nc.nc4```.
For example, for the platform 'GT' and year 2003, the name of the NetCDF file is: ```58GT_CTD_2003.nc.nc4.```

## Retrieval of DDS information
After the set-up, the data dimensions can be accessed through the Data Distribution Service (DDS), to understand the size of the datasets in an efficient way, without downloading all data into local memory. The dimensions under consideration for this NetCDF files are: 'TIME', 'LATITUDE', 'LONGITUDE', 'DEPTH', 'POSITION'.

## Visual Analysis: Load and Plot Positions only
The objective of this section is to visualise the geograhical positions of the data for each platform, and to perform some filtering operations based on locations and time queries. This is possible using only the necessary information retrieved from the DDS. The key dimensions that are used for the position analysis are: 'TIME', 'LATITUDE', 'LONGITUDE'. 

### Create Position Dictionary and Dataframe 
The *position_dict* is a dictionary that is generated by iteratively reading the url of each platform, selecting only with 'TIME', 'LATITUDE', 'LONGITUDE' dimensions. In the dictionary are saved:
* the actual data, loaded into an xarray for data handling, analysis and visualisation
* the campaign's main attributes: *platform code & name*, *data type*, *title*, *instrument*, *longitude* & *latitude*, and *vertical min & max*)

A position dataframe is then generated per each platform, to match and combine the three 'TIME', 'LATITUDE', 'LONGITUDE' dimensions for each measurement. Subsequently, the platform-specific dataframes are combined in a *position_df* dataframe. An overview of the structure of the *position_df* dataframe is given below (showing the first and last 5 element):

Merged dataframe with all platforms. Total of 3209 measurement locations

  <tr>
   <td>
   </td>
   <td>**Longitude**

   </td>
   <td>**Latitude**

   </td>
   <td>**Time**

   </td>
   <td>**Platform**

   </td>
   <td>**Index_ABS**

   </td>
  </tr>
  <tr>
   <td>**Index_Relative**

   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>**0**

   </td>
   <td>4.6155

   </td>
   <td>60.755299

   </td>
   <td>2003-01-07 05:25:57

   </td>
   <td>AA

   </td>
   <td>0

   </td>
  </tr>
  <tr>
   <td>**1**

   </td>
   <td>4.4483

   </td>
   <td>60.748299

   </td>
   <td>2003-01-07 06:05:08

   </td>
   <td>AA

   </td>
   <td>1

   </td>
  </tr>
  <tr>
   <td>**2**

   </td>
   <td>4.2853

   </td>
   <td>60.751499

   </td>
   <td>2003-01-07 08:34:00

   </td>
   <td>AA

   </td>
   <td>2

   </td>
  </tr>
  <tr>
   <td>**3**

   </td>
   <td>4.1170

   </td>
   <td>60.747799

   </td>
   <td>2003-01-07 09:18:06

   </td>
   <td>AA

   </td>
   <td>3

   </td>
  </tr>
  <tr>
   <td>**4**

   </td>
   <td>3.9475

   </td>
   <td>60.752201

   </td>
   <td>2003-01-07 09:59:37

   </td>
   <td>AA

   </td>
   <td>4

   </td>
  </tr>
  <tr>
   <td>**...**

   </td>
   <td>...

   </td>
   <td>...

   </td>
   <td>...

   </td>
   <td>...

   </td>
   <td>...

   </td>
  </tr>
  <tr>
   <td>**945**

   </td>
   <td>15.6965

   </td>
   <td>71.253998

   </td>
   <td>2003-12-17 11:01:51

   </td>
   <td>JH

   </td>
   <td>3204

   </td>
  </tr>
  <tr>
   <td>**946**

   </td>
   <td>12.5057

   </td>
   <td>71.252701

   </td>
   <td>2003-12-17 22:14:57

   </td>
   <td>JH

   </td>
   <td>3205

   </td>
  </tr>
  <tr>
   <td>**947**

   </td>
   <td>13.0053

   </td>
   <td>71.751503

   </td>
   <td>2003-12-18 03:03:55

   </td>
   <td>JH

   </td>
   <td>3206

   </td>
  </tr>
  <tr>
   <td>**948**

   </td>
   <td>14.9853

   </td>
   <td>71.743301

   </td>
   <td>2003-12-18 07:15:07

   </td>
   <td>JH

   </td>
   <td>3207

   </td>
  </tr>
  <tr>
   <td>**949**

   </td>
   <td>17.0693

   </td>
   <td>71.751701

   </td>
   <td>2003-12-18 11:53:00

   </td>
   <td>JH

   </td>
   <td>3208

   </td>
  </tr>

### Plot Positions 

### Filter Positions
* By bounding box (BBOX)
* By BBOX and Month of collection
* By BBOX and Time (eg hour) of collection

## Processing: Load and Plot all needed Data (Variables and their Attributes)

### Create Data Dictionary (*data_dict*) 

### Filter Data
* Filtered data by BBOX and One Variable
* Filtered data by BBOX (All Variables)
* Filtered data by BBOX and One Variable, within a DEPTH range
* Filtered data by BBOX (All Variables), within a DEPTH range

### Reference Plots
* Plotting individual Variables per individual Platform
* Plotting individual Variables across aggregated Platforms




